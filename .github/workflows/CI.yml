name: CI
on:
  push:
    branches:
      - main
    tags: ['*']
  pull_request:
  schedule:
    - cron:  '28 0,6,12,18 * * *'
concurrency:
  # Skip intermediate builds: always.
  # Cancel intermediate builds: only if it is a pull request build.
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ startsWith(github.ref, 'refs/pull/') }}
jobs:
  # test:
  #   name: ${{ matrix.test_group }}
  #   runs-on: ubuntu-latest
  #   if: github.event_name != 'schedule'
  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       test_group:
  #         - 'basic'
  #         - 'rrules'
  #         - 'integration_testing/misc'
  #         - 'integration_testing/diff_tests'
  #         - 'integration_testing/distributions'
  #         - 'integration_testing/gp'
  #         - 'integration_testing/special_functions'
  #         - 'integration_testing/array'
  #         - 'integration_testing/turing'
  #   steps:
  #     - uses: actions/checkout@v4
  #     - uses: julia-actions/setup-julia@v1
  #       with:
  #         version: '1'
  #         arch: x64
  #         include-all-prereleases: true
  #     - uses: julia-actions/cache@v1
  #     - uses: julia-actions/julia-buildpkg@v1
  #     - uses: julia-actions/julia-runtest@v1
  #       env:
  #         TEST_GROUP: ${{ matrix.test_group }}
  perf:
    name: "Performance (${{ matrix.perf_group }})"
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        perf_group:
          - 'hand_written'
          - 'derived'
    steps:
      - uses: actions/checkout@v4
      - uses: julia-actions/setup-julia@v1
        with:
          version: '1'
          arch: x64
          include-all-prereleases: true
      - uses: julia-actions/cache@v1
      - uses: julia-actions/julia-buildpkg@v1
      - run: julia --project=bench --eval 'include("bench/run_benchmarks.jl"); main()'
        env:
          PERF_GROUP: ${{ matrix.perf_group }}
        shell: bash
  compperf:
    name: "Performance (inter-AD)"
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
    steps:
      - uses: actions/checkout@v4
      - uses: julia-actions/setup-julia@v1
        with:
          version: '1'
          arch: x64
          include-all-prereleases: true
      - uses: julia-actions/cache@v1
      - uses: julia-actions/julia-buildpkg@v1
      - run: mkdir bench_results
      - run: julia --project=bench --eval 'include("bench/run_benchmarks.jl"); main()'
        env:
          PERF_GROUP: 'comparison'
          GKSwstype: '100'
        shell: bash
      - uses: actions/upload-artifact@v4
        with:
          name: benchmarking-results
          path: bench_results/
      # - run: |
      #     text="this is line one
      #     this is line two
      #     this is line three"
      #     echo "$text" > benchmark_results.txt
      - name: Read file content
        id: read-file
        run: |
          {
            echo "table<<EOF"
            cat benchmark_results.txt
            cat benchmark_results.txt
            echo "EOF"
          } >> $GITHUB_OUTPUT
      - id: post-report-as-pr-comment
        name: Post Report as Pull Request Comment
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.number }}
          body: "```\n${{ steps.read-file.outputs.table }}\n```"
